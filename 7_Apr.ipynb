{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ans no1\n",
        "#What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
        "\n",
        "Polynomial functions are a type of mathematical function used in machine learning algorithms to model non-linear relationships between features and the target variable. Kernel functions, on the other hand, are used in support vector machines (SVMs) to map the input data into a higher dimensional feature space.\n",
        "\n",
        "In SVMs, the choice of kernel function determines the type of decision boundary that can be drawn between the classes. The polynomial kernel function is one of the types of kernel functions used in SVMs. It maps the input data into a higher dimensional space using polynomial functions. In this way, the polynomial kernel function can be used to create non-linear decision boundaries in the original feature space.\n",
        "\n",
        "Thus, we can say that polynomial functions are used within kernel functions to create non-linear decision boundaries in machine learning algorithms, specifically in support vector machines.\n"
      ],
      "metadata": {
        "id": "hmpzojDXPBDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans no2\n",
        "\n",
        "#How can we implement an SVM with a polynomial kernel in Python using Scikit-learn\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:, :2]  # Extract the first two features\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train an SVM with a polynomial kernel\n",
        "clf = svm.SVC(kernel='poly', degree=3)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the performance of the model\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "print('Accuracy:{:.3f}'.format( accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2p2hv5QbRI1p",
        "outputId": "88fea240-d786-41c5-d04e-5dc84f931848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:0.733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans no3\n",
        "#How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
        "\n",
        "In Support Vector Regression (SVR), the parameter epsilon determines the margin of error tolerated by the model. An increase in the value of epsilon results in a wider margin and thus allows more training points to be considered as support vectors.\n",
        "\n",
        "Therefore, increasing the value of epsilon will typically increase the number of support vectors in SVR. This is because the model is allowed to fit to a larger range of values, and thus more data points are required to define the boundaries of the margin.\n",
        "\n",
        "However, it is important to note that the number of support vectors is also influenced by other factors such as the complexity of the model and the distribution of the data. Therefore, the relationship between epsilon and the number of support vectors may not always be straightforward and should be evaluated on a case-by-case basis.\n"
      ],
      "metadata": {
        "id": "yk-ejPGeSeNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans no4\n",
        "#How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
        "\n",
        "Support Vector Regression (SVR) is a machine learning algorithm that is commonly used for regression analysis. The performance of SVR is affected by several parameters, including the choice of kernel function, C parameter, epsilon parameter, and gamma parameter. Let's discuss each parameter and how it affects the performance of SVR:\n",
        "\n",
        "Kernel Function: The kernel function specifies the form of the decision boundary that separates the data points. Popular kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid. The choice of kernel function depends on the nature of the data and the problem at hand. For example, the linear kernel is suitable for linearly separable data, while the RBF kernel is suitable for non-linearly separable data.\n",
        "\n",
        "C Parameter: The C parameter controls the trade-off between the margin and the number of misclassifications. A smaller value of C creates a larger margin, which reduces the risk of overfitting but may result in more misclassifications. On the other hand, a larger value of C results in a smaller margin, which may lead to overfitting but reduces the number of misclassifications.\n",
        "\n",
        "Epsilon Parameter: The epsilon parameter controls the size of the margin of error around the regression line. A smaller value of epsilon results in a narrow margin, which makes the model less tolerant to errors but improves its accuracy. Conversely, a larger value of epsilon results in a wider margin, which makes the model more tolerant to errors but reduces its accuracy.\n",
        "\n",
        "Gamma Parameter: The gamma parameter controls the shape of the decision boundary. A smaller value of gamma results in a more flexible decision boundary, which may overfit the data. On the other hand, a larger value of gamma results in a more rigid decision boundary, which may underfit the data.\n",
        "\n",
        "In general, the choice of these parameters depends on the nature of the data and the problem at hand. For example, if the data is highly non-linear, a non-linear kernel such as RBF or polynomial may be more suitable. If the model is overfitting the data, reducing the value of C or gamma may help. If the model is underfitting the data, increasing the value of C or gamma may help. The epsilon parameter should be tuned to balance the trade-off between accuracy and tolerance to errors."
      ],
      "metadata": {
        "id": "xs9rNqULpNb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ans no5\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "dataset=load_iris()\n",
        "df=sns.load_dataset('iris')\n"
      ],
      "metadata": {
        "id": "lS-Tl1GBRaL1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=dataset.target\n",
        "X=df.drop(\"species\",axis=1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)\n"
      ],
      "metadata": {
        "id": "exYZwPWHO2ML"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "_4e3UpzvP-7X"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.svm import SVC\n",
        "# clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "# clf.fit(X, y)\n",
        "# # Pipeline(steps=[('standardscaler', StandardScaler()),\n",
        "# #                 ('svc', SVC(gamma='auto'))])\n"
      ],
      "metadata": {
        "id": "4spGkk48RIkF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(kernel='rbf', C=1, gamma='scale', random_state=42)\n",
        "\n",
        "svc.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "KPVCwyZIW0ra",
        "outputId": "e337d916-561e-4256-9886-c594079e2dba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svc.predict(X_test)"
      ],
      "metadata": {
        "id": "SWLKlV_dXBEK"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Computing the accuracy score of the classifier on the testing set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZVHGW5IXVrV",
        "outputId": "daf77ecb-4d0f-464e-f220-3cd123f57a34"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Defining the parameter grid to search over\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'] + [0.1, 1, 10]\n",
        "}\n",
        "\n",
        "# Creating an instance of the SVC classifier\n",
        "svc = SVC()\n",
        "\n",
        "# Creating an instance of GridSearchCV with 5-fold cross-validation\n",
        "grid_search = GridSearchCV(svc, param_grid, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fitting the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Printing the best hyperparameters and the corresponding score\n",
        "print('Best hyperparameters:', grid_search.best_params_)\n",
        "print('Best score:', grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQSrlBtaXov8",
        "outputId": "4e5c1822-b28b-4f2d-a742-ba1a1364b96f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best score: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svc=SVC(C= 1, kernel= 'linear')\n",
        "svc.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ytPK66WcZI9h",
        "outputId": "a3a4fc70-cc73-4f47-fbc9-3eccd52c4c8d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pickle\n",
        "\n",
        "# Saving the trained classifier to a file\n",
        "with open('svc_classifier.pkl', 'wb') as file:\n",
        "    pickle.dump(svc, file)\n",
        "\n"
      ],
      "metadata": {
        "id": "Mz01h8WRZiBu"
      },
      "execution_count": 52,
      "outputs": []
    }
  ]
}