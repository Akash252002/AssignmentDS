{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JR8m3QWwyVYA"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(filename='9mar.log',level=logging.INFO,format='%(asctime)s,%(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no1\")\n",
        "# Ans no1\n",
        "\n",
        "'''\n",
        "The Probability Mass Function (PMF) and Probability Density Function (PDF) are\n",
        " two common ways of describing the probability distribution of a random variable.\n",
        "\n",
        "A probability mass function (PMF) is a function that maps each possible value of\n",
        " a discrete random variable to the probability of that value occurring.\n",
        "\n",
        "In other words, the PMF gives the probability of each possible outcome. \n",
        "For example, if we have a fair six-sided die, the PMF would assign a probability \n",
        "of 1/6 to each of the values 1, 2, 3, 4, 5, and 6.\n",
        "\n",
        "A probability density function (PDF) is a function that describes the relative \n",
        "likelihood of a continuous random variable taking on a certain value. \n",
        "\n",
        "Unlike the PMF, which gives the probability of each individual value, the PDF gives \n",
        "the probability of a range of values. \n",
        "\n",
        "The area under the curve of the PDF between two points gives the probability of the random variable taking on a value in that range. \n",
        "\n",
        "For example, the PDF of a standard normal distribution (a continuous probability distribution with mean 0 and v ariance 1) \n",
        "is given by the function:\n",
        "\n",
        "f(x) = (1/√(2π))e^(-(x^2)/2)\n",
        "\n",
        "This PDF describes the probability density of a continuous random variable x, \n",
        "where x can take on any value between negative infinity and positive infinity. \n",
        "\n",
        "The area under the curve of this PDF between two points gives the probability of the random variable\n",
        "taking on a value in that range. \n",
        "\n",
        "For example, the probability of the random variable taking on a value between -1 and 1 is the area under \n",
        "the curve of the PDF between -1 and 1\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "OKim8kPOyv3D",
        "outputId": "572f4a16-acd5-4ce3-8603-1fdf400195b7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Probability Mass Function (PMF) and Probability Density Function (PDF) are\\n two common ways of describing the probability distribution of a random variable.\\n\\nA probability mass function (PMF) is a function that maps each possible value of\\n a discrete random variable to the probability of that value occurring.\\n\\nIn other words, the PMF gives the probability of each possible outcome. \\nFor example, if we have a fair six-sided die, the PMF would assign a probability \\nof 1/6 to each of the values 1, 2, 3, 4, 5, and 6.\\n\\nA probability density function (PDF) is a function that describes the relative \\nlikelihood of a continuous random variable taking on a certain value. \\n\\nUnlike the PMF, which gives the probability of each individual value, the PDF gives \\nthe probability of a range of values. \\n\\nThe area under the curve of the PDF between two points gives the probability of the random variable taking on a value in that range. \\n\\nFor example, the PDF of a standard normal distribution (a continuous probability distribution with mean 0 and v ariance 1) \\nis given by the function:\\n\\nf(x) = (1/√(2π))e^(-(x^2)/2)\\n\\nThis PDF describes the probability density of a continuous random variable x, \\nwhere x can take on any value between negative infinity and positive infinity. \\n\\nThe area under the curve of this PDF between two points gives the probability of the random variable\\ntaking on a value in that range. \\n\\nFor example, the probability of the random variable taking on a value between -1 and 1 is the area under \\nthe curve of the PDF between -1 and 1\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no2\")\n",
        "# Ans no2\n",
        "\n",
        "'''\n",
        "The Cumulative Density Function (CDF) is a function that gives the probability that a \n",
        "random variable X is less than or equal to a certain value x. \n",
        "\n",
        "Mathematically, it is defined as:\n",
        "\n",
        "F(x) = P(X ≤ x)\n",
        "\n",
        "The CDF is a cumulative function because it accumulates the probabilities of all the possible outcomes up to a certain point. \n",
        "It gives the probability of X being less than or equal to a certain value, \n",
        "which means that it can also be used to find the probability of X being greater than a certain value. \n",
        "This is given by:\n",
        "\n",
        "P(X > x) = 1 - F(x)\n",
        "\n",
        "For example, let's say we have a fair six-sided die. The CDF of this die is given by:\n",
        "\n",
        "F(x) = P(X ≤ x)\n",
        "\n",
        "If we want to find the probability of rolling a 4 or less, we can use the CDF:\n",
        "\n",
        "F(4) = P(X ≤ 4) = 4/6 = 2/3\n",
        "\n",
        "So the probability of rolling a 4 or less is 2/3.\n",
        "\n",
        "The CDF is a useful tool in probability and statistics because it provides a way to \n",
        "calculate probabilities for a range of values, rather than just a single value.\n",
        "It also allows us to easily calculate probabilities for values greater than or less than a certain value. \n",
        "Additionally, the CDF can be used to calculate other statistical measures, \n",
        "such as the median and quartiles of a distribution.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "-DXpYtTOvtzL",
        "outputId": "2cab1217-5427-42da-d3c3-6f76713633b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nThe Cumulative Density Function (CDF) is a function that gives the probability that a \\nrandom variable X is less than or equal to a certain value x. \\n\\nMathematically, it is defined as:\\n\\nF(x) = P(X ≤ x)\\n\\nThe CDF is a cumulative function because it accumulates the probabilities of all the possible outcomes up to a certain point. \\nIt gives the probability of X being less than or equal to a certain value, \\nwhich means that it can also be used to find the probability of X being greater than a certain value. \\nThis is given by:\\n\\nP(X > x) = 1 - F(x)\\n\\nFor example, let's say we have a fair six-sided die. The CDF of this die is given by:\\n\\nF(x) = P(X ≤ x)\\n\\nIf we want to find the probability of rolling a 4 or less, we can use the CDF:\\n\\nF(4) = P(X ≤ 4) = 4/6 = 2/3\\n\\nSo the probability of rolling a 4 or less is 2/3.\\n\\nThe CDF is a useful tool in probability and statistics because it provides a way to \\ncalculate probabilities for a range of values, rather than just a single value.\\nIt also allows us to easily calculate probabilities for values greater than or less than a certain value. \\nAdditionally, the CDF can be used to calculate other statistical measures, \\nsuch as the median and quartiles of a distribution.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no3\")\n",
        "# Ans no3\n",
        "\n",
        "'''\n",
        "The normal distribution, also known as the Gaussian distribution or the bell curve,\n",
        "is a commonly used statistical model in many fields, including physics, engineering, economics, psychology, and biology. \n",
        "Some examples of situations where the normal distribution might be used as a model include:\n",
        "\n",
        "The heights of people in a population.\n",
        "The weights of objects produced by a factory.\n",
        "The test scores of students in a class.\n",
        "The IQ scores of a population.\n",
        "The error terms in a regression model.\n",
        "\n",
        "The normal distribution is characterized by two parameters:\n",
        "\n",
        "the mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, \n",
        "while the standard deviation determines the spread of the distribution.\n",
        "\n",
        "If μ is shifted to the right, the entire distribution will shift to the right. Similarly, \n",
        "if μ is shifted to the left, the entire distribution will shift to the left.\n",
        "\n",
        "The standard deviation, σ, determines the width of the distribution. A small value of σ will result in a narrow, \n",
        "tall distribution, while a large value of σ will result in a wide, short distribution.\n",
        "\n",
        "Together, the mean and standard deviation of a normal distribution determine the shape of the distribution. \n",
        "A normal distribution is symmetric about the mean, meaning that the probability of \n",
        "observing a value above the mean is the same as the probability of observing a value below the mean. \n",
        "Additionally, about 68% of the data falls within one standard deviation of the mean, \n",
        "about 95% of the data falls within two standard deviations of the mean, \n",
        "and about 99.7% of the data falls within three standard deviations of the mean, regardless of the value of μ.'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "5X6oOGYKwBTV",
        "outputId": "72807ac8-c450-4579-8422-b1bbf7ffaf41"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe normal distribution, also known as the Gaussian distribution or the bell curve,\\nis a commonly used statistical model in many fields, including physics, engineering, economics, psychology, and biology. \\nSome examples of situations where the normal distribution might be used as a model include:\\n\\nThe heights of people in a population.\\nThe weights of objects produced by a factory.\\nThe test scores of students in a class.\\nThe IQ scores of a population.\\nThe error terms in a regression model.\\n\\nThe normal distribution is characterized by two parameters:\\n\\nthe mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, \\nwhile the standard deviation determines the spread of the distribution.\\n\\nIf μ is shifted to the right, the entire distribution will shift to the right. Similarly, \\nif μ is shifted to the left, the entire distribution will shift to the left.\\n\\nThe standard deviation, σ, determines the width of the distribution. A small value of σ will result in a narrow, \\ntall distribution, while a large value of σ will result in a wide, short distribution.\\n\\nTogether, the mean and standard deviation of a normal distribution determine the shape of the distribution. \\nA normal distribution is symmetric about the mean, meaning that the probability of \\nobserving a value above the mean is the same as the probability of observing a value below the mean. \\nAdditionally, about 68% of the data falls within one standard deviation of the mean, \\nabout 95% of the data falls within two standard deviations of the mean, \\nand about 99.7% of the data falls within three standard deviations of the mean, regardless of the value of μ.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no4\")\n",
        "# Ans no4\n",
        "\n",
        "'''\n",
        "Normal distribution is one of the most important probability distributions in statistics\n",
        "and is widely used in various fields due to its properties ofsymmetry, unimodality, \n",
        "and well-defined mean and standard deviation. It is also known as Gaussian distribution, \n",
        "named after the mathematician Carl Friedrich Gauss, who first described its properties.\n",
        "\n",
        "The importance of the normal distribution lies in the fact that it serves as a foundation \n",
        "for many statistical methods and techniques,particularly in inferential statistics. \n",
        "For example, many statistical tests and confidence intervals assume that the data follows a normal distribution. \n",
        "Moreover, the central limit theorem, which states that the distribution of the sum of independent, \n",
        "identically distributed random variables tends toward a normal distribution, is a fundamental concept in statistics.\n",
        "\n",
        "Here are a few real-life examples of normal distribution:\n",
        "\n",
        "Height: The heights of people in a population tend to follow a normal distribution. \n",
        "The mean height of a population may vary from country to country or region to region, \n",
        "but the distribution is usually bell-shaped.\n",
        "\n",
        "Weight: Body weight of a large population, \n",
        "with no significant outliers, can be modeled by a normal distribution.\n",
        "\n",
        "Test Scores: Scores on standardized tests, such as the SAT or GRE, are typically normally distributed. \n",
        "This allows for the easy calculation of percentiles and identifying those students\n",
        "who performed particularly well or poorly on the exam.\n",
        "\n",
        "IQ Scores: Intelligence quotient (IQ) scores are also known to follow a normal distribution \n",
        "with a mean of 100 and a standard deviation of 15.\n",
        "\n",
        "Financial Markets: The daily returns of stocks or other financial instruments tend to follow a normal distribution, \n",
        "which is the basis for many quantitative trading strategies.\n",
        "\n",
        "In conclusion, normal distribution is a crucial tool in statistical analysis and modeling, \n",
        "and its properties are widely used in various fields, ranging from social sciences to finance and engineering. \n",
        "Its importance lies in its ability to provide a useful approximation for many real-life phenomena and \n",
        "simplify statistical calculations.'''\n"
      ],
      "metadata": {
        "id": "1jdrkAaYwM3q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "ed04f951-2ec1-4ba9-9ca4-27e5e7e99504"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nNormal distribution is one of the most important probability distributions in statistics\\nand is widely used in various fields due to its properties ofsymmetry, unimodality, \\nand well-defined mean and standard deviation. It is also known as Gaussian distribution, \\nnamed after the mathematician Carl Friedrich Gauss, who first described its properties.\\n\\nThe importance of the normal distribution lies in the fact that it serves as a foundation \\nfor many statistical methods and techniques,particularly in inferential statistics. \\nFor example, many statistical tests and confidence intervals assume that the data follows a normal distribution. \\nMoreover, the central limit theorem, which states that the distribution of the sum of independent, \\nidentically distributed random variables tends toward a normal distribution, is a fundamental concept in statistics.\\n\\nHere are a few real-life examples of normal distribution:\\n\\nHeight: The heights of people in a population tend to follow a normal distribution. \\nThe mean height of a population may vary from country to country or region to region, \\nbut the distribution is usually bell-shaped.\\n\\nWeight: Body weight of a large population, \\nwith no significant outliers, can be modeled by a normal distribution.\\n\\nTest Scores: Scores on standardized tests, such as the SAT or GRE, are typically normally distributed. \\nThis allows for the easy calculation of percentiles and identifying those students\\nwho performed particularly well or poorly on the exam.\\n\\nIQ Scores: Intelligence quotient (IQ) scores are also known to follow a normal distribution \\nwith a mean of 100 and a standard deviation of 15.\\n\\nFinancial Markets: The daily returns of stocks or other financial instruments tend to follow a normal distribution, \\nwhich is the basis for many quantitative trading strategies.\\n\\nIn conclusion, normal distribution is a crucial tool in statistical analysis and modeling, \\nand its properties are widely used in various fields, ranging from social sciences to finance and engineering. \\nIts importance lies in its ability to provide a useful approximation for many real-life phenomena and \\nsimplify statistical calculations.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no5\")\n",
        "# Ans no5\n",
        "\n",
        "'''\n",
        "Bernoulli distribution is a probability distribution that models a single experiment \n",
        "that can have only two possible outcomes, usually labeled as success (S) or failure (F), \n",
        "with a probability of success denoted by p and probability of failure denoted by q = 1-p. \n",
        "\n",
        "It is named after the Swiss mathematician Jacob Bernoulli \n",
        "who introduced this distribution in his work on probability in the 17th century.\n",
        "\n",
        "The Bernoulli distribution can be written as:\n",
        "\n",
        "P(X=1) = p, and P(X=0) = q\n",
        "\n",
        "where X is a random variable that takes the value 1 if the event of interest (success) occurs,\n",
        "and 0 if it does not occur (failure). The distribution of X is said to follow a Bernoulli distribution.\n",
        "\n",
        "An example of Bernoulli distribution is the toss of a coin. \n",
        "The coin can land either heads (success) or tails (failure) with a \n",
        "certain probability of success (for example, p = 0.5 for a fair coin).\n",
        "\n",
        "The binomial distribution can be written as:\n",
        "\n",
        "P(X=k) = (n choose k) p^k (1-p)^(n-k)\n",
        "\n",
        "where X is the number of successes in n trials, k is a non-negative integer less\n",
        " than or equal to n, and (n choose k) is the binomial coefficient.\n",
        "\n",
        "The key difference between the Bernoulli distribution and the binomial distribution \n",
        "is that the Bernoulli distribution models a single trial, \n",
        "while the binomial distribution models a series of independent and identically distributed Bernoulli trials. \n",
        "The Bernoulli distribution is a special case of the binomial distribution, where n=1.\n",
        "\n",
        "In summary, Bernoulli distribution is used to model a single experiment with two possible outcomes, \n",
        "while binomial distribution models a series of independent and identically \n",
        "distributed Bernoulli trials with a fixed number of trials.'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "dV_OYFykwRcR",
        "outputId": "ddf5bcf2-febb-4059-be58-0f3558677383"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nBernoulli distribution is a probability distribution that models a single experiment \\nthat can have only two possible outcomes, usually labeled as success (S) or failure (F), \\nwith a probability of success denoted by p and probability of failure denoted by q = 1-p. \\n\\nIt is named after the Swiss mathematician Jacob Bernoulli \\nwho introduced this distribution in his work on probability in the 17th century.\\n\\nThe Bernoulli distribution can be written as:\\n\\nP(X=1) = p, and P(X=0) = q\\n\\nwhere X is a random variable that takes the value 1 if the event of interest (success) occurs,\\nand 0 if it does not occur (failure). The distribution of X is said to follow a Bernoulli distribution.\\n\\nAn example of Bernoulli distribution is the toss of a coin. \\nThe coin can land either heads (success) or tails (failure) with a \\ncertain probability of success (for example, p = 0.5 for a fair coin).\\n\\nThe binomial distribution can be written as:\\n\\nP(X=k) = (n choose k) p^k (1-p)^(n-k)\\n\\nwhere X is the number of successes in n trials, k is a non-negative integer less\\n than or equal to n, and (n choose k) is the binomial coefficient.\\n\\nThe key difference between the Bernoulli distribution and the binomial distribution \\nis that the Bernoulli distribution models a single trial, \\nwhile the binomial distribution models a series of independent and identically distributed Bernoulli trials. \\nThe Bernoulli distribution is a special case of the binomial distribution, where n=1.\\n\\nIn summary, Bernoulli distribution is used to model a single experiment with two possible outcomes, \\nwhile binomial distribution models a series of independent and identically \\ndistributed Bernoulli trials with a fixed number of trials.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no6\")\n",
        "# Ans no6\n",
        "\n",
        "'''\n",
        "To calculate the probability that a randomly selected observation from a normal \n",
        "distribution with mean 50 and standard deviation 10 will be greater than 60, \n",
        "we need to use the standard normal distribution and convert the data to z-scores.\n",
        "\n",
        "The formula to calculate the z-score is:\n",
        "\n",
        "z = (x - μ) / σ\n",
        "\n",
        "where x is the value we are interested in, μ is the mean of the distribution, \n",
        "and σ is the standard deviation of the distribution.\n",
        "\n",
        "In this case, x = 60, μ = 50, and σ = 10, so:\n",
        "\n",
        "z = (60 - 50) / 10 = 1\n",
        "\n",
        "Using a standard normal distribution table or calculator,\n",
        " we can find the probability that a randomly selected observation \n",
        " from a standard normal distribution is greater than 1:\n",
        "\n",
        "P(Z > 1) ≈ 0.1587\n",
        "\n",
        "Therefore, the probability that a randomly selected observation \n",
        "from the given normal distribution is greater than 60 is approximately 0.1587 or 15.87%.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "eYtufSu5wmeE",
        "outputId": "80160e7d-6baf-4202-cc72-9df064763722"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTo calculate the probability that a randomly selected observation from a normal \\ndistribution with mean 50 and standard deviation 10 will be greater than 60, \\nwe need to use the standard normal distribution and convert the data to z-scores.\\n\\nThe formula to calculate the z-score is:\\n\\nz = (x - μ) / σ\\n\\nwhere x is the value we are interested in, μ is the mean of the distribution, \\nand σ is the standard deviation of the distribution.\\n\\nIn this case, x = 60, μ = 50, and σ = 10, so:\\n\\nz = (60 - 50) / 10 = 1\\n\\nUsing a standard normal distribution table or calculator,\\n we can find the probability that a randomly selected observation \\n from a standard normal distribution is greater than 1:\\n\\nP(Z > 1) ≈ 0.1587\\n\\nTherefore, the probability that a randomly selected observation \\nfrom the given normal distribution is greater than 60 is approximately 0.1587 or 15.87%.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no7\")\n",
        "# Ans no7\n",
        "\n",
        "'''\n",
        "The uniform distribution is a probability distribution that is defined over a continuous range of values \n",
        "and assigns equal probability density to each possible value within that range. \n",
        "In other words, the probability of observing any value within the range is the same.\n",
        "\n",
        "For example, imagine you have a fair six-sided die. The outcome of rolling the die can be any of the \n",
        "six possible values: 1, 2, 3, 4, 5, or 6. If the die is fair, \n",
        "then the probability of obtaining any particular outcome is 1/6 or approximately 0.1667.\n",
        "\n",
        "This is an example of a discrete uniform distribution because the possible outcomes are discrete (i.e., individual numbers), \n",
        "and each outcome has an equal probability of occurring.\n",
        "\n",
        "Now, imagine that you have a continuous range of values, \n",
        "such as the height of a randomly selected adult in a certain population. \n",
        "The height could be any value within a range, say between 150 and 190 cm. \n",
        "If the distribution of heights in this population is uniform, \n",
        "then the probability of selecting an individual with a height between 160 and 170 cm\n",
        "would be the same as selecting someone with a height between 170 and 180 cm, and so on.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "aZAUCu_txsaS",
        "outputId": "76b0fa03-8329-4edb-95a2-56c7e9f6a02c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe uniform distribution is a probability distribution that is defined over a continuous range of values \\nand assigns equal probability density to each possible value within that range. \\nIn other words, the probability of observing any value within the range is the same.\\n\\nFor example, imagine you have a fair six-sided die. The outcome of rolling the die can be any of the \\nsix possible values: 1, 2, 3, 4, 5, or 6. If the die is fair, \\nthen the probability of obtaining any particular outcome is 1/6 or approximately 0.1667.\\n\\nThis is an example of a discrete uniform distribution because the possible outcomes are discrete (i.e., individual numbers), \\nand each outcome has an equal probability of occurring.\\n\\nNow, imagine that you have a continuous range of values, \\nsuch as the height of a randomly selected adult in a certain population. \\nThe height could be any value within a range, say between 150 and 190 cm. \\nIf the distribution of heights in this population is uniform, \\nthen the probability of selecting an individual with a height between 160 and 170 cm\\nwould be the same as selecting someone with a height between 170 and 180 cm, and so on.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no8\")\n",
        "# Ans no8\n",
        "\n",
        "'''\n",
        "The z-score (also known as standard score or normal deviate) is a measure of \n",
        "how many standard deviations an observation \n",
        "or data point is above or below the mean of a population. \n",
        "It is calculated by subtracting the population mean from the observation and then dividing it \n",
        "by the population standard deviation. The formula for z-score is:\n",
        "\n",
        "z = (X - μ) / σ\n",
        "\n",
        "where X is the value of the observation, μ is the population mean, \n",
        "and σ is the population standard deviation.\n",
        "\n",
        "The z-score is important in statistics for several reasons, including:\n",
        "\n",
        "Standardization: The z-score provides a way to standardize or normalize data, \n",
        "which makes it easier to compare data sets that have different scales or units of measurement.\n",
        "\n",
        "Normal distribution: The z-score is particularly useful for analyzing data that \n",
        "follows a normal distribution, which is a bell-shaped curve that is symmetrical around the mean.\n",
        " In a normal distribution, \n",
        "a z-score of 0 corresponds to the mean, and positive or negative z-scores \n",
        "indicate how far a data point is from the mean in standard deviation units.\n",
        "\n",
        "Outlier detection: The z-score can also be used to identify outliers or \n",
        "unusual data points that are more than a certain number \n",
        "of standard deviations away from the mean.\n",
        "\n",
        "Hypothesis testing: The z-score is commonly used in hypothesis testing to determine the probability\n",
        "of observing a particular sample mean or difference in means assuming a normal distribution.\n",
        "\n",
        "Overall, the z-score is a fundamental tool in statistical analysis that helps to standardize data, \n",
        "identify outliers, and make inferences about population parameters based on sample statistics.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "6Wyjm1Apy-QW",
        "outputId": "9d54129f-2883-4de1-d884-a071dcb3039d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe z-score (also known as standard score or normal deviate) is a measure of how many standard deviations an observation \\nor data point is above or below the mean of a population. \\nIt is calculated by subtracting the population mean from the observation and then dividing it \\nby the population standard deviation. The formula for z-score is:\\n\\nz = (X - μ) / σ\\n\\nwhere X is the value of the observation, μ is the population mean, and σ is the population standard deviation.\\n\\nThe z-score is important in statistics for several reasons, including:\\n\\nStandardization: The z-score provides a way to standardize or normalize data, \\nwhich makes it easier to compare data sets that have different scales or units of measurement.\\n\\nNormal distribution: The z-score is particularly useful for analyzing data that follows a normal distribution, \\nwhich is a bell-shaped curve that is symmetrical around the mean. In a normal distribution, \\na z-score of 0 corresponds to the mean, and positive or negative z-scores indicate how far a data point is from the mean in standard deviation units.\\n\\nOutlier detection: The z-score can also be used to identify outliers or unusual data points that are more than a certain number \\nof standard deviations away from the mean.\\n\\nHypothesis testing: The z-score is commonly used in hypothesis testing to determine the probability\\nof observing a particular sample mean or difference in means assuming a normal distribution.\\n\\nOverall, the z-score is a fundamental tool in statistical analysis that helps to standardize data, \\nidentify outliers, and make inferences about population parameters based on sample statistics.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no9\")\n",
        "# Ans no9\n",
        "\n",
        "\n",
        "'''\n",
        "The Central Limit Theorem (CLT) is a statistical theory that states that, \n",
        "under certain conditions, the distribution of the sample mean of a random variable \n",
        "approaches a normal distribution as the sample size increases, \n",
        "regardless of the distribution of the original variable.\n",
        "\n",
        "In simpler terms, the Central Limit Theorem states that if you take a \n",
        "large number of samples from any population with a finite mean and variance, \n",
        "and calculate the mean of each sample, then the distribution of those sample \n",
        "means will be approximately normal, regardless of the shape of the original population distribution.\n",
        "\n",
        "The significance of the Central Limit Theorem is that it allows us to make statistical \n",
        "inferences about the population mean, \n",
        "even when the population distribution is not known. Specifically, the CLT enables us to:\n",
        "\n",
        "Make inferences about the population mean based on a sample mean, \n",
        "using the properties of the normal distribution.\n",
        "\n",
        "Use the sample mean and standard deviation to construct confidence intervals \n",
        "and hypothesis tests for the population mean.\n",
        "\n",
        "Apply statistical methods that assume a normal distribution to non-normally distributed data,\n",
        " provided that the sample size is large enough.\n",
        "\n",
        "Provide a theoretical justification for the effectiveness of some statistical methods, \n",
        "such as t-tests and ANOVA, which rely on the assumption of normality.\n",
        "\n",
        "Overall, the Central Limit Theorem is a fundamental concept in statistics that allows \n",
        "us to make reliable inferences about population parameters, \n",
        "even when the population distribution is unknown or non-normal.\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "-Xppk95XzRzf",
        "outputId": "3f612061-e39a-4ce8-b00b-a0d3e38709b3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Central Limit Theorem (CLT) is a statistical theory that states that, \\nunder certain conditions, the distribution of the sample mean of a random variable \\napproaches a normal distribution as the sample size increases, \\nregardless of the distribution of the original variable.\\n\\nIn simpler terms, the Central Limit Theorem states that if you take a \\nlarge number of samples from any population with a finite mean and variance, \\nand calculate the mean of each sample, then the distribution of those sample \\nmeans will be approximately normal, regardless of the shape of the original population distribution.\\n\\nThe significance of the Central Limit Theorem is that it allows us to make statistical \\ninferences about the population mean, \\neven when the population distribution is not known. Specifically, the CLT enables us to:\\n\\nMake inferences about the population mean based on a sample mean, \\nusing the properties of the normal distribution.\\n\\nUse the sample mean and standard deviation to construct confidence intervals \\nand hypothesis tests for the population mean.\\n\\nApply statistical methods that assume a normal distribution to non-normally distributed data,\\n provided that the sample size is large enough.\\n\\nProvide a theoretical justification for the effectiveness of some statistical methods, \\nsuch as t-tests and ANOVA, which rely on the assumption of normality.\\n\\nOverall, the Central Limit Theorem is a fundamental concept in statistics that allows \\nus to make reliable inferences about population parameters, \\neven when the population distribution is unknown or non-normal.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logging.info(\"writing the ans no10\")\n",
        "# Ans no10\n",
        "'''\n",
        "The Central Limit Theorem (CLT) is a fundamental theorem in statistics that applies to the distribution of sample means.\n",
        " However, to apply the CLT, certain assumptions must be met. These assumptions include:\n",
        "\n",
        "Independence: The observations in the sample must be independent of each other.\n",
        " In other words, the value of one observation should not depend on the value of another observation.\n",
        "\n",
        "Sample size: The sample size should be sufficiently large. \n",
        "There is no fixed rule for what constitutes a large sample size, but a common guideline is that the sample size should be at least 30.\n",
        "\n",
        "Identical distribution: The observations in the sample should be drawn from the same population, with the same mean and variance.\n",
        "\n",
        "Finite variance: The population variance should be finite, which means that the observations in the population should not be spread out too widely.\n",
        "\n",
        "Random sampling: The sample should be selected at random from the population.\n",
        "\n",
        "It is important to note that violating any of these assumptions can affect the validity of the Central Limit Theorem. \n",
        "For example, \n",
        "if the observations are not independent, or the sample size is too small, or the population variance is infinite, \n",
        "the distribution of the sample means may not approach a normal distribution even as the sample size increases.\n",
        "\n",
        "Overall, the Central Limit Theorem is a powerful tool in statistics, \n",
        "but it requires careful consideration of the assumptions involved in order to be applied correctly.'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "9Dt-CnHPzh-W",
        "outputId": "8b20479f-c71e-40ed-fa00-66df3a62af05"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Central Limit Theorem (CLT) is a fundamental theorem in statistics that applies to the distribution of sample means.\\n However, to apply the CLT, certain assumptions must be met. These assumptions include:\\n\\nIndependence: The observations in the sample must be independent of each other.\\n In other words, the value of one observation should not depend on the value of another observation.\\n\\nSample size: The sample size should be sufficiently large. \\nThere is no fixed rule for what constitutes a large sample size, but a common guideline is that the sample size should be at least 30.\\n\\nIdentical distribution: The observations in the sample should be drawn from the same population, with the same mean and variance.\\n\\nFinite variance: The population variance should be finite, which means that the observations in the population should not be spread out too widely.\\n\\nRandom sampling: The sample should be selected at random from the population.\\n\\nIt is important to note that violating any of these assumptions can affect the validity of the Central Limit Theorem. \\nFor example, \\nif the observations are not independent, or the sample size is too small, or the population variance is infinite, \\nthe distribution of the sample means may not approach a normal distribution even as the sample size increases.\\n\\nOverall, the Central Limit Theorem is a powerful tool in statistics, \\nbut it requires careful consideration of the assumptions involved in order to be applied correctly.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}